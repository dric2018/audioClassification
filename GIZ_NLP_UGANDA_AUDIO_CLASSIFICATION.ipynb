{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GIZ-NLP-UGANDA-AUDIO-CLASSIFICATION.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Hy7pf1ToQ79EyMtLk67XRh0G18uPgRG",
      "authorship_tag": "ABX9TyOIUoCg3MgroYzG6h8ILe32",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dric2018/audioClassification/blob/main/GIZ_NLP_UGANDA_AUDIO_CLASSIFICATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynf82MalzP_n",
        "outputId": "17bef854-4a47-4a0f-f652-cd2328ac597a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D_IVyo-2h6H",
        "outputId": "87240ebc-bf75-4cd6-8292-530ea066ab4e"
      },
      "source": [
        "%%writefile init.sh\n",
        "pip install git+https://github.com/eaedk/testing-zindi-package.git --q\n",
        "\n",
        "apt-get install unzip unrar p7zip-full\n",
        "python3 -m pip install patool --q\n",
        "python3 -m pip install pyunpack --q\n",
        "pip install --q torch\n",
        "pip install --q pytorch-lightning \n",
        "pip install librosa\n",
        "pip install efficientnet-pytorch\n",
        "pip install torchaudio\n",
        "pip install -U pandas --q # upgrade pandas\n",
        "pip install swifter\n",
        "mkdir /content/models && mkdir -p data/datasets/images\n",
        "\n",
        "python init.py --username I_am_Zeus_AI --download #Connects the user and download the dataset from zindi\n",
        "unzip --q data/raw/audio_files.zip -d data/\n",
        "unzip --q data/raw/AdditionalUtterances.zip -d data/\n",
        "unzip --q data/raw/nlp_keywords_29Oct2020.zip -d data/\n",
        "\n",
        "python utils.py --data_path /content/data/ --csv_path /content/data/ --create_train_df True --create_spectrograms True --specs_path /content/data/datasets\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting init.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUR3YGI45eyR",
        "outputId": "08c410e2-b8c6-4afd-baa1-f4abb13c6c19"
      },
      "source": [
        "%%writefile init.py\n",
        "\n",
        "import os, sys, gc, glob\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zindi import user as zuser\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Logging phase')\n",
        "\n",
        "parser.add_argument('--username', type=str, help='Your Zindi username')\n",
        "parser.add_argument('--prefix', type=str, default='/content/drive/My Drive/GIZ_NLP_AGRI_Challenge/', help=\"***\")\n",
        "parser.add_argument('--data', type=str, default='data/', help=\"***\")\n",
        "parser.add_argument('--seed', type=int, default=2020, help='randomness factor')\n",
        "parser.add_argument('--download', action='store_true', help=\"\")\n",
        "\n",
        "def download(args):\n",
        "\tuser = zuser.Zindian(args.username)\n",
        "\tuser.which_challenge\n",
        "\tuser.select_a_challenge()\n",
        "\tuser.download_dataset(args.data)\n",
        "\n",
        "def info(args):\n",
        "\ttrain = pd.read_csv(args.prefix + 'BaseTrain.csv')\n",
        "\tfull = pd.read_csv(args.prefix + 'Train.csv')\n",
        "\tadd = pd.read_csv(args.prefix + 'AddTrain.csv')\n",
        "\n",
        "\tlung_words = add.target.unique()\n",
        "\teng_words = [w for w in train.target.unique() if w not in lung_words]\n",
        "\n",
        "\tdicts = {\"base data\": train, \"add data\": add, \"full data\": full}\n",
        "\n",
        "\twith open(args.prefix + \"info.txt\", \"w\") as f:\n",
        "\t\tfor name, df in dicts.items():\n",
        "\t\t\tinfo = f\"##{name}##. \\nIt contains {df.target.nunique()} unique classes .\\n\"\n",
        "\t\t\tinfo += f\"Shape: {df.shape}\\n\\n\"\n",
        "\t\t\tf.write(info)\n",
        "\t\tf.close()\n",
        "  \n",
        "\n",
        "def main(parser):\n",
        "\targs = parser.parse_args()\n",
        "\n",
        "\tif args.download: download(args)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tmain(parser)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting init.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_IO4lEA1gP7",
        "outputId": "dd394421-3ce5-4024-bf35-27dabdb77e67"
      },
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from tqdm import tqdm \n",
        "from pyunpack import Archive\n",
        "import argparse\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt \n",
        "import swifter\n",
        "from scipy import signal\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data_path',  type=str, help='data source directory')\n",
        "parser.add_argument('--destination_path',  type=str, help='data destination directory')\n",
        "parser.add_argument('--extract_files', default=False, type=bool, help='execute extraction or not')\n",
        "parser.add_argument('--kind', default='7z', type=str, help='For .7z files extraction')\n",
        "parser.add_argument('--create_train_df', default=True, type=bool, help='Create a training dataframe or not')\n",
        "parser.add_argument('--csv_path', type=str, help='Csv files path')\n",
        "parser.add_argument('--specs_path', type=str, help='Spectrograms files path')\n",
        "parser.add_argument('--create_spectrograms', default=True, type=bool, help='Create log spectrogram or not')\n",
        "parser.add_argument('--sample_csv_path', type=str, help='sample submission csv file')\n",
        "\n",
        "\n",
        "def extract_files(data_path:str, destination_path:str):\n",
        "    files = os.listdir(data_path)\n",
        "    dest = os.path.join(destination_path)\n",
        "\n",
        "    os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "    for fn in tqdm(files):\n",
        "        if fn.split('.')[-1] == \"zip\":\n",
        "            try :\n",
        "                with ZipFile(os.path.join(data_path, fn), \"r\") as zip_ref:\n",
        "                    for file_ in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist()), desc=\"Extrating files\"):\n",
        "\n",
        "                        # Extract each file to another directory\n",
        "                        # If you want to extract to current working directory, don't specify path\n",
        "                        zip_ref.extract(member=file_, path=dest)\n",
        "                    print(f'[INFO] successfully extracted files from {fn}')\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f'[ERROR] {ex}')\n",
        "\n",
        "\n",
        "def extract_files_v1(data_path:str, destination_path:str):\n",
        "    files = os.listdir(data_path)\n",
        "    dest = os.path.join(destination_path)\n",
        "\n",
        "    os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "    for fn in tqdm(files):\n",
        "        if fn.split('.')[-1] == \"7z\":\n",
        "            try :\n",
        "                print(f'[INFO] Extracting files from {fn}')\n",
        "\n",
        "                tqdm(Archive(os.path.join(data_path, fn)).extractall(dest), desc=len(os.listdir(os.path.join(data_path, fn))))\n",
        "                print(f'[INFO] successfully extracted files from {fn}')\n",
        "\n",
        "            except Exception as ex:\n",
        "                print(f'[ERROR] {ex}')\n",
        "\n",
        "\n",
        "\n",
        "def calc_duration(file_path):\n",
        "    signal, sr = librosa.load(file_path)\n",
        "    return signal.shape[0] / sr\n",
        "    \n",
        "\n",
        "def label_to_int(label, class_dict):\n",
        "    return class_dict[label]\n",
        "\n",
        "\n",
        "def create_train_dataframe(csv_path, data_path):\n",
        "    if ('Train.csv' in os.listdir(csv_path))  or ('train.csv' in os.listdir(csv_path)):\n",
        "        try:\n",
        "            df = pd.read_csv(os.path.join(csv_path, 'Train.csv'))\n",
        "        except:\n",
        "            df = pd.read_csv(os.path.join(csv_path, 'train.csv'))\n",
        "\n",
        "\n",
        "        folder_list = os.listdir(data_path)\n",
        "        files_list = []\n",
        "        labels = []\n",
        "\n",
        "        for folder in folder_list:\n",
        "            if folder != 'audio_files':\n",
        "                try:\n",
        "                    keywords = os.listdir(os.path.join(data_path, folder))\n",
        "                    for keyword in keywords:\n",
        "                        files = os.listdir(os.path.join(data_path, folder, keyword))\n",
        "                        files_list += [os.path.join(folder, keyword, fn) for fn in files ]\n",
        "                        labels += [keyword for _ in range(len(os.listdir(os.path.join(data_path, folder, keyword)))) ]\n",
        "                except:\n",
        "                    pass\n",
        "                \n",
        "        \n",
        "\n",
        "        df = df.append(pd.DataFrame({\n",
        "            'fn' : files_list,\n",
        "            'label' : labels\n",
        "        }), ignore_index=True)\n",
        "\n",
        "\n",
        "        df['fn'] = data_path +'/'+ df['fn']\n",
        "        df['duration'] = df.swifter.progress_bar(enable=True, desc='computing audio durations').apply(lambda row : calc_duration(row.fn), axis=1) # use all available cpu cores\n",
        "        df['label'] = df.swifter.progress_bar(enable=True, desc='Converting labels to ints').apply(lambda row : label_to_int(label=row.label, class_dict={l:idx for idx, l in enumerate(df.label.unique().tolist())}) , axis=1)# use all available cpu cores\n",
        "        df.to_csv(os.path.join(csv_path, 'final_train.csv'), index=False)\n",
        "\n",
        "\n",
        "\n",
        "def log_specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
        "\n",
        "    \"\"\"\n",
        "    Borrowing log spec function from https://www.kaggle.com/davids1992/data-visualization-and-investigation\n",
        "    \"\"\"\n",
        "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
        "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
        "    freqs, _, spec = signal.spectrogram(audio,\n",
        "                                    fs=sample_rate,\n",
        "                                    window='hann',\n",
        "                                    nperseg=nperseg,\n",
        "                                    noverlap=noverlap,\n",
        "                                    detrend=False)\n",
        "    return freqs, np.log(spec.T.astype(np.float32) + eps)\n",
        "\n",
        "\n",
        "def wav2img(wav_path, targetdir='', figsize=(4,4)):\n",
        "    \"\"\"\n",
        "    takes in wave file path\n",
        "    and the fig size. Default 4,4 will make images 288 x 288\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=figsize)    \n",
        "    # use soundfile library to read in the wave files\n",
        "    sound, samplerate  = librosa.load(wav_path)\n",
        "    _, spectrogram = log_specgram(sound, samplerate)\n",
        "    \n",
        "    ## create output path\n",
        "    output_file = wav_path.split('/')[-1].split('.wav')[0]\n",
        "    output_file = targetdir +'/'+ output_file\n",
        "    #plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
        "    plt.imsave('%s.png' % output_file, spectrogram)\n",
        "    plt.close()\n",
        "\n",
        "    return output_file+'.png'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.extract_files:\n",
        "        if args.kind == 'zip':\n",
        "            try:\n",
        "                extract_files(args.data_path, args.destination_path)\n",
        "            except Exception as ex:\n",
        "                raise ex\n",
        "        else:\n",
        "            try:\n",
        "                extract_files_v1(args.data_path, args.destination_path)\n",
        "            except Exception as ex:\n",
        "                raise ex\n",
        "\n",
        "    if args.create_train_df:\n",
        "        try:\n",
        "            df = create_train_dataframe(args.csv_path, args.data_path)\n",
        "        except Exception as ex:\n",
        "            print(ex)\n",
        "\n",
        "    if args.create_spectrograms:\n",
        "        try:\n",
        "            # train spectrograms\n",
        "            img_dir = args.specs_path+'/images'\n",
        "            df['spec_path'] = img_dir\n",
        "            os.makedirs(img_dir, exist_ok=True)\n",
        "            for row in tqdm(df.iterrows(), total=len(df), desc='Creating specs'):\n",
        "                output_file = wav2img(wav_path=row[1].fn, targetdir=img_dir)\n",
        "                df.at[row[0], 'spec_path'] = output_file\n",
        "\n",
        "            # save dataframe with specs paths\n",
        "            df.to_csv(os.path.join(args.csv_path, 'final_train.csv'), index=False)\n",
        "            \n",
        "            # test spectrograms\n",
        "            sample = pd.read_csv(args.sample_csv_path)\n",
        "            sample['fn'] = args.data_path +'/'+ sample['fn']\n",
        "            sample['spec_path'] = img_dir\n",
        "\n",
        "            for row in tqdm(sample.iterrows(), total=len(sample), desc='Creating specs'):\n",
        "                output_file = wav2img(wav_path=row[1].fn, targetdir=img_dir)\n",
        "                sample.at[row[0], 'spec_path'] = output_file\n",
        "\n",
        "            sample.to_csv(os.path.join(args.csv_path, 'final_test.csv'), index=False)\n",
        "            \n",
        "        except:\n",
        "            pass"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moyLKz2m8QPq",
        "outputId": "409f64dc-d68a-4147-f3f7-47b857b95488"
      },
      "source": [
        "%%writefile datasets.py\n",
        "import torch \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from keras.utils import to_categorical\n",
        "import librosa\n",
        "import os\n",
        "import albumentations as al\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pandas as pd \n",
        "from pytorch_lightning import seed_everything\n",
        "import numpy as np\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, images_path:str,df:pd.DataFrame, transforms=None,  task = 'train', num_classes=193, one_hot=False, **kwargs):\n",
        "        super(AudioDataset, self).__init__()\n",
        "\n",
        "        self.task = task \n",
        "        self.df = df\n",
        "        try:\n",
        "            self.class_dict = {label:idx for idx,label in enumerate(self.df.label.unique().tolist())}\n",
        "        except:\n",
        "            pass\n",
        "        self.transforms = transforms\n",
        "        self.one_hot = one_hot\n",
        "        self.images_path = images_path\n",
        "        self.num_classes = num_classes\n",
        "        self.log_specs = os.listdir(self.images_path)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        wav_path = self.df.iloc[index].fn\n",
        "        file_ = wav_path.split('/')[-1].split('.wav')[0]\n",
        "        file_path = self.images_path +'/'+ file_ +'.png'\n",
        "        \n",
        "        # load spectrogram\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)        \n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(image=img)['image']\n",
        "        \n",
        "        sample = {'image' : torch.tensor(img, dtype=torch.float)}\n",
        "\n",
        "        if self.task == 'train':\n",
        "            label = self.df.iloc[index].label\n",
        "            if self.one_hot:\n",
        "                sample.update({\n",
        "                    'label' : torch.tensor(to_categorical(label, self.num_classes), dtype=torch.float)\n",
        "                })            \n",
        "            else:\n",
        "                sample.update({\n",
        "                    'label' : torch.tensor(label, dtype=torch.long)\n",
        "                })\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing datasets.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmZrm3NS8Q7W",
        "outputId": "d68abdf1-c871-4cad-ad9a-7bc02b6cf541"
      },
      "source": [
        "%%writefile models.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd \n",
        "import random\n",
        "import albumentations as al\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, loggers, seed_everything \n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "from datasets import AudioDataset\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AudioClassifier(pl.LightningModule):\n",
        "    def __init__(self, pretrained=True, out_size=193,img_size=224, lr=0.0023182567385564073, arch_name='resnet34'):\n",
        "        super(AudioClassifier, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        if 'efficient' in self.hparams.arch_name:\n",
        "            self.arch = Efficientnet.from_pretrained(self.hparams.arch_name)\n",
        "\n",
        "            #change firs conv layer to accept grayscale images\n",
        "            head = torch.nn.Conv2d(1, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n",
        "            head.weight = torch.nn.Parameter(self.arch.conv1.weight.sum(dim=1, keepdim=True))\n",
        "            self.conv1 = head\n",
        "\n",
        "            # add our own  classifier \n",
        "            self.num_last_ftrs = getattr(self.arch, 'fc').in_features\n",
        "            self.arch.fc = nn.Sequential(\n",
        "                nn.Dropout(.5),\n",
        "                nn.Linear(self.num_last_ftrs, out_size)\n",
        "            ) \n",
        "            torch.nn.init.xavier_normal_(self.arch.fc[1].weight)\n",
        "\n",
        "        else:\n",
        "            self.arch = getattr(models, arch_name)(pretrained)\n",
        "\n",
        "            head = torch.nn.Conv2d(1, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n",
        "            head.weight = torch.nn.Parameter(self.arch.conv1.weight.sum(dim=1, keepdim=True))\n",
        "\n",
        "            self.arch.conv1 = head\n",
        "            # classifier part\n",
        "            self.num_last_ftrs = getattr(self.arch, 'fc').in_features\n",
        "            self.arch.fc = nn.Sequential(\n",
        "                nn.Dropout(.5),\n",
        "                nn.Linear(self.num_last_ftrs, out_size)\n",
        "            ) \n",
        "            torch.nn.init.xavier_normal_(self.arch.fc[1].weight)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.arch(x.view(-1, 1, self.hparams.img_size, self.hparams.img_size))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = torch.optim.SGD(self.parameters(), lr=self.hparams.lr)\n",
        "        return opt\n",
        "\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch['image'], batch['label']\n",
        "        logits = self(x)\n",
        "\n",
        "        logLoss = self.get_loss(logits=logits, targets=y)\n",
        "        acc = self.get_acc(logits=logits, targets=y)\n",
        "\n",
        "        # logging \n",
        "        self.log('train_acc', acc, on_epoch=True, on_step=False, prog_bar=True)\n",
        "        self.log('train_logLoss', logLoss, on_epoch=True, on_step=True, prog_bar=False)\n",
        "\n",
        "        return {'loss':logLoss, 'train_logloss':logLoss, 'train_acc':acc}\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch['image'], batch['label']\n",
        "        logits = self(x)\n",
        "\n",
        "        val_loss = self.get_loss(logits=logits, targets=y)\n",
        "        val_acc = self.get_acc(logits=logits, targets=y)\n",
        "\n",
        "        # logging \n",
        "        self.log('val_acc', val_acc, on_epoch=True, on_step=False, prog_bar=True)\n",
        "        self.log('val_logLoss', val_loss, on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "        return {'val_logLoss':val_loss, 'val_acc':val_acc}\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch['image'], batch['label']\n",
        "        logits = self(x)\n",
        "\n",
        "        test_loss = self.get_loss(logits=logits, targets=y)\n",
        "        test_acc = self.get_acc(logits=logits, targets=y)\n",
        "\n",
        "        # logging \n",
        "        self.log('test_acc', test_acc, on_epoch=True, on_step=False, prog_bar=True)\n",
        "        self.log('test_logLoss', test_loss, on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "        return {'test_logLoss':test_loss, 'test_acc':test_acc}\n",
        "\n",
        "\n",
        "\n",
        "    def get_acc(self, logits, targets):\n",
        "\n",
        "        preds = nn.functional.softmax(logits, dim=1).argmax(1)\n",
        "\n",
        "        acc = (preds == targets).float().mean()\n",
        "        return acc\n",
        "\n",
        "\n",
        "    def get_loss(self, logits, targets):\n",
        "        \n",
        "        loss = nn.CrossEntropyLoss()(logits, targets)\n",
        "        return loss\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing models.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldC43HEv8Rbv",
        "outputId": "e708cca9-0960-494d-ffcd-7a770a99cb96"
      },
      "source": [
        "%%writefile train.py\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "import numpy as np\n",
        "import gc\n",
        "import pandas as pd \n",
        "import random\n",
        "from models import AudioClassifier\n",
        "from datasets import AudioDataset\n",
        "import albumentations as al\n",
        "import os\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, loggers, seed_everything \n",
        "import argparse\n",
        "\n",
        "\n",
        "# arguments parser config\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--train_csv_path', type=str, help='Train csv file')\n",
        "parser.add_argument('--lr', type=float, default=0.0023182567385564073,  help='Learning rate for model training')\n",
        "parser.add_argument('--gpus', type=int, default=1,  help='Number of gpus to use for training')\n",
        "parser.add_argument('--kfold', type=int, default=5,  help='number of folds to use for cross validation')\n",
        "parser.add_argument('--train_batch_size', type=int, default=16,  help='Training batch size')\n",
        "parser.add_argument('--test_batch_size', type=int, default=16,  help='Test/Evaluation batch size')\n",
        "parser.add_argument('--num_epochs', type=int, default=40,  help='Number of epochs for training')\n",
        "parser.add_argument('--img_size', type=int, default=224,  help='input image size')\n",
        "parser.add_argument('--seed_value', type=int, default=2020,  help='Seed value for reproducibility')\n",
        "parser.add_argument('--specs_images_path', type=str, help='Direcetory containing log spectrograms images')\n",
        "parser.add_argument('--save_models_to', type=str, help='Directory to save trained models to')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_folds(data:pd.DataFrame, args, n_folds = 10, target_col='label'):\n",
        "  data['fold'] = 0\n",
        "\n",
        "  fold = StratifiedKFold(n_splits = n_folds, random_state=args.seed_value)\n",
        "  for i, (tr, vr) in enumerate(fold.split(data, data[target_col])):\n",
        "    data.loc[vr, 'fold'] = i\n",
        "\n",
        "  return data, n_folds\n",
        "\n",
        "\n",
        "def run_fold(fold, train_df, args,size=(224, 224), arch='resnet18', pretrained=True,   path='MODELS/', data_transforms=None):\n",
        "  \n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  fold_train = train_df[train_df.fold != fold].reset_index(drop=True)\n",
        "  fold_val = train_df[train_df.fold == fold].reset_index(drop=True)\n",
        "\n",
        "  train_ds = AudioDataset(images_path=args.specs_images_path, df=fold_train, transforms=data_transforms['train'])\n",
        "  val_ds = AudioDataset(images_path=args.specs_images_path, df=fold_val, transforms=data_transforms['train'])\n",
        "\n",
        "  trainloader = DataLoader(train_ds, batch_size=args.train_batch_size, shuffle=True , num_workers=os.cpu_count())\n",
        "  validloader = DataLoader(val_ds, batch_size=args.test_batch_size, shuffle=False , num_workers=os.cpu_count())\n",
        "\n",
        "  del train_ds\n",
        "  del val_ds\n",
        "  del fold_train\n",
        "  del fold_val\n",
        "\n",
        "  model = AudioClassifier(arch_name=arch, lr=args.lr, pretrained=pretrained)\n",
        "\n",
        "  tb_logger = loggers.TensorBoardLogger(save_dir='./runs', name='ZINDI-GIZ-NLP-AGRI-KEYWORDS', version=fold)\n",
        "\n",
        "  ckpt_callback = pl.callbacks.ModelCheckpoint(filename=f'ZINDI-GIZ-NLP-AGRI-KEYWORDS-{model.hparams.arch_name}-{fold}-based', \n",
        "                                               dirpath=path, \n",
        "                                               monitor='val_logLoss', \n",
        "                                               mode='min')\n",
        "  \n",
        "  trainer = Trainer(max_epochs=args.num_epochs, gpus=args.gpus, logger=tb_logger, callbacks=[ckpt_callback])\n",
        "\n",
        "  trainer.fit(model, trainloader, validloader)\n",
        "\n",
        "\n",
        "  gc.collect() # collect garbage\n",
        "\n",
        "  return trainer.logged_metrics\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  _ = seed_everything(args.seed_value)\n",
        "  # data augmentations\n",
        "  data_transforms = {\n",
        "      'train': al.Compose([\n",
        "              al.Resize(args.img_size, args.img_size),\n",
        "              al.Cutout(p=.6, max_h_size=15, max_w_size=10, num_holes=4),\n",
        "              al.Rotate(limit=35, p=.04),\n",
        "              al.Normalize((0.1307,), (0.3081,))\n",
        "      ]),\n",
        "\n",
        "      'test': al.Compose([\n",
        "              al.Resize(args.img_size, args.img_size),\n",
        "              al.Cutout(p=.6, max_h_size=15, max_w_size=10, num_holes=4),\n",
        "              al.Normalize((0.1307,), (0.3081,))\n",
        "      ])\n",
        "  }\n",
        "\n",
        "  df = pd.read_csv(args.train_csv_path)\n",
        "  train, n_folds = make_folds(n_folds=args.kfold, args=args, data=df)\n",
        "  \n",
        "  # traiining loop\n",
        "  best_fold = 0\n",
        "  avg_log_loss = 0.0\n",
        "  best_logloss = np.inf\n",
        "\n",
        "  for fold in range(n_folds):\n",
        "\n",
        "    print('')\n",
        "    print('*'*18)\n",
        "    print(f'Training on fold {fold}')\n",
        "    print('*'*18)\n",
        "    metrics = run_fold(fold=fold, train_df=train, args=args ,size=(224, 224), arch='resnet34', pretrained=True,   path=args.save_models_to, data_transforms=data_transforms)\n",
        "    \n",
        "    print(metrics)\n",
        "    break\n",
        "    print('')\n",
        "    print('*'*75)\n",
        "    print(f'\\t\\t Results for Fold {fold}')\n",
        "    print('-'*75)\n",
        "\n",
        "    print(f'> Train Acc : \\t{train_acc} \\t| Valid Acc : {val_acc}')\n",
        "    print(f'> Train logloss : {train_loss} \\t| Valid logloss : {val_loss}')\n",
        "    print('-'*75)\n",
        "    print(f'\\t\\t Results for Fold {fold}')\n",
        "    print('*'*75)\n",
        "    if metrics['val_logLoss'] < best_logloss:\n",
        "        best_logloss = metrics['val_logLoss']\n",
        "        best_fold = fold\n",
        "        avg_log_loss += metrics['val_logLoss']\n",
        "    else:\n",
        "        avg_log_loss += metrics['val_logLoss']\n",
        "\n",
        "  print(f'[INFO] raining done ! Avg LogLoss : {avg_log_loss / n_folds}')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jgYVnbJ8Rd-",
        "outputId": "8b0e64e0-4006-4848-d56e-ccb37ec95861"
      },
      "source": [
        "%%writefile inference.py\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd \n",
        "import random\n",
        "import albumentations as al\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, loggers, seed_everything \n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "from datasets import AudioDataset\n",
        "from models import AudioClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "import argparse\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# arguments parser config\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--test_csv_path', type=str, help='test csv file')\n",
        "parser.add_argument('--sample_csv_path', type=str, help='sample submission csv file')\n",
        "parser.add_argument('--gpus', type=int, default=1,  help='Number of gpus to use for inference')\n",
        "parser.add_argument('--train_batch_size', type=int, default=64,  help='batch size used for training')\n",
        "parser.add_argument('--test_batch_size', type=int, default=16,  help='Test/Evaluation batch size')\n",
        "parser.add_argument('--n_tta', type=int, default=3,  help='Number of Test time Augmentations (TTA)')\n",
        "parser.add_argument('--kfold', type=int, default=3,  help='Number of folds used for training')\n",
        "parser.add_argument('--img_size', type=int, default=224,  help='input image size')\n",
        "parser.add_argument('--seed_value', type=int, default=2020,  help='Seed value for reproducibility')\n",
        "parser.add_argument('--specs_images_path', type=str, help='Direcetory containing log spectrograms images')\n",
        "parser.add_argument('--save_resulting_file_to', type=str, help='Directory to save predictions file')\n",
        "parser.add_argument('--arch', type=str, help='Model architecture to load for inference')\n",
        "parser.add_argument('--num_epochs', type=int, default=40,  help='Number of epochs for training')\n",
        "parser.add_argument('--models_path', type=str, help='Direcetory containing models checkpoints')\n",
        "parser.add_argument('--lr', type=float, default=0.013182567385564073,  help='Learning rate for model training')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_models(models_path, arch=None, n_folds=3, device='cuda'):\n",
        "\n",
        "    models = []\n",
        "    for i in range(n_folds):\n",
        "        models.append( AudioClassifier(arch_name=arch) )\n",
        "        models[i].to(device)\n",
        "        try:\n",
        "            models[i].load_from_checkpoint(os.path.join(models_path, f'ZINDI-GIZ-NLP-AGRI-KEYWORDS-{arch}-{i}-based.ckpt'))\n",
        "        except:\n",
        "            models[i].load_from_checkpoint(os.path.join(models_path, f'ZINDI-GIZ-NLP-AGRI-KEYWORDS-{arch}-{i}-based-v0.ckpt'))\n",
        "        models[i].eval()\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "\n",
        "def predict(test_df, images_path, batch_size=16, n_folds=3, transforms=None, n_tta=3, device='cuda', models=None):\n",
        "    # create test AudioDataset\n",
        "    test_ds = AudioDataset(images_path=images_path, task='test', df=test_df, transforms=transforms)\n",
        "    test_dl = DataLoader(dataset=test_ds, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    predictions_labels = []\n",
        "    predictions_proba = []\n",
        "\n",
        "    out = None\n",
        "\n",
        "    for data in tqdm(test_dl):\n",
        "        x = data['image'].to(device)\n",
        "\n",
        "        for i in range(n_folds):\n",
        "            if i == 0: out = models[i](x)\n",
        "            else: out += models[i](x)\n",
        "\n",
        "        out /= n_folds\n",
        "        out = F.softmax(input=out, dim=1)\n",
        "        out_labels = out.argmax(1)\n",
        "        out_probas = out.detach().cpu().numpy()\n",
        "\n",
        "        \n",
        "        predictions_labels += out_labels.tolist()\n",
        "        predictions_proba += out_probas.tolist()\n",
        "\n",
        "    return predictions_labels ,predictions_proba\n",
        "\n",
        "\n",
        "\n",
        "def make_submission_file(sub:pd.DataFrame,predictions_proba=None, submissions_folder=None, params=None):\n",
        "    submission = pd.DataFrame()\n",
        "    words = sub.columns[1:]\n",
        "    submission['fn'] = sub['fn']\n",
        "    for i, label in enumerate(words):\n",
        "        submission[label] = 0.\n",
        "    for i, label in enumerate(words):\n",
        "        submission.loc[:,label] = np.array(predictions_proba)[:,i]\n",
        "\n",
        "    train_batch_size,_, n_folds, img_size, n_epochs, arch = params.values()\n",
        "\n",
        "    csv_file = f'GIZ_SIZE_{img_size}_arch_{arch}_n_folds_{n_folds}_num_epochs_{n_epochs}_train_bs_{train_batch_size}.csv'\n",
        "    submission.to_csv(os.path.join(submissions_folder, csv_file), index=False)\n",
        "\n",
        "    print(f'[INFO] Submission file save to {os.path.join(submissions_folder, csv_file)}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    _ = seed_everything(args.seed_value)\n",
        "    # data augmentations\n",
        "    data_transforms = {\n",
        "        'train': al.Compose([\n",
        "                al.Resize(args.img_size, args.img_size),\n",
        "                al.Cutout(p=.6, max_h_size=15, max_w_size=10, num_holes=4),\n",
        "                al.Rotate(limit=35, p=.04),\n",
        "                al.Normalize((0.1307,), (0.3081,))\n",
        "        ]),\n",
        "\n",
        "        'test': al.Compose([\n",
        "                al.Resize(args.img_size, args.img_size),\n",
        "                al.Cutout(p=.6, max_h_size=15, max_w_size=10, num_holes=4),\n",
        "                al.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "    }\n",
        "\n",
        "    test = pd.read_csv(args.test_csv_path)\n",
        "    sample = pd.read_csv(args.sample_csv_path)\n",
        "\n",
        "    # load models\n",
        "    models = load_models(models_path=args.models_path, n_folds=args.kfold, arch=args.arch)\n",
        "    # make predictions\n",
        "    predictions_labels, predictions_proba = predict(test_df=test, \n",
        "                                                    images_path=args.specs_images_path,\n",
        "                                                    batch_size=args.test_batch_size, \n",
        "                                                    n_folds=args.kfold, \n",
        "                                                    transforms=data_transforms['test'], \n",
        "                                                    n_tta=args.n_tta, \n",
        "                                                    device='cuda', \n",
        "                                                    models=models)\n",
        "\n",
        "    params = {\n",
        "        'train_batch_size': args.train_batch_size,\n",
        "        'test_batch_size':args.test_batch_size,\n",
        "        'kfold': args.kfold, \n",
        "        'img_size': args.img_size,\n",
        "        'epochs': args.num_epochs,\n",
        "        'arch' : args.arch\n",
        "    }\n",
        "\n",
        "    make_submission_file(sub=sample,predictions_proba=predictions_proba, submissions_folder=args.save_resulting_file_to, params=params)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting inference.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y9TntanAF7A",
        "outputId": "6dd0ec7c-07a6-44ec-b17e-e3e8da8280ce"
      },
      "source": [
        "%%writefile inference.sh\n",
        "\n",
        "python inference.py --test_csv_path /content/data/final_test.csv --models_path /content/models --sample_csv_path /content/data/SampleSubmission.csv --arch 'resnet34' --save_resulting_file_to /content/ --test_batch_size 16 --specs_images_path /content/data/datasets/images"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing inference.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4yKTJ18AGQf",
        "outputId": "f6f6a6f3-4b63-4723-c7c9-56d39226d82c"
      },
      "source": [
        "%%writefile train.sh\n",
        "\n",
        "python train.py --train_csv_path /content/data/final_train.csv --gpus 1 --test_batch_size 32 --train_batch_size 128 --kfold 3 --num_epochs 50 --img_size 224 --specs_images_path /content/data/datasets/images --save_models_to /content/models --seed_value 2020 --lr 0.0023182567385564073\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing train.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyWVvFqc-ANl"
      },
      "source": [
        "# Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Knsz0A0o_w"
      },
      "source": [
        "!chmod +x init.sh && chmod +x train.sh && chmod +x inference.sh"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngCTBhGWA1d2",
        "outputId": "576b8d5c-62e9-4fd5-97d3-f0dcaaa0e2da"
      },
      "source": [
        "!./init.sh"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for zindi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "p7zip-full is already the newest version (16.02+dfsg-6).\n",
            "unrar is already the newest version (1:5.5.8-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.15.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (50.3.2)\n",
            "Requirement already satisfied: efficientnet-pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet-pytorch) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet-pytorch) (0.18.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet-pytorch) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet-pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet-pytorch) (0.8)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio) (0.18.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio) (3.7.4.3)\n",
            "Requirement already satisfied: swifter in /usr/local/lib/python3.6/dist-packages (1.0.7)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.6/dist-packages (from swifter) (5.7.3)\n",
            "Requirement already satisfied: parso>0.4.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (0.7.1)\n",
            "Requirement already satisfied: modin[ray]>=0.8.1.1 in /usr/local/lib/python3.6/dist-packages (from swifter) (0.8.2)\n",
            "Requirement already satisfied: dask[dataframe]>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (2.12.0)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (4.41.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (1.1.4)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0cloudpickle>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from swifter) (7.5.1)\n",
            "Requirement already satisfied: bleach>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from swifter) (3.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from modin[ray]>=0.8.1.1->swifter) (20.4)\n",
            "Requirement already satisfied: ray>=1.0.0; extra == \"ray\" in /usr/local/lib/python3.6/dist-packages (from modin[ray]>=0.8.1.1->swifter) (1.0.1.post1)\n",
            "Requirement already satisfied: pyarrow==1.0; extra == \"ray\" in /usr/local/lib/python3.6/dist-packages (from modin[ray]>=0.8.1.1->swifter) (1.0.0)\n",
            "Requirement already satisfied: partd>=0.3.10; extra == \"dataframe\" in /usr/local/lib/python3.6/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.1.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0; extra == \"dataframe\" in /usr/local/lib/python3.6/dist-packages (from dask[dataframe]>=2.10.0->swifter) (0.8.4)\n",
            "Requirement already satisfied: numpy>=1.13.0; extra == \"dataframe\" in /usr/local/lib/python3.6/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.18.5)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"dataframe\" in /usr/local/lib/python3.6/dist-packages (from dask[dataframe]>=2.10.0->swifter) (0.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.0->swifter) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.0->swifter) (2018.9)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.0.8)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (3.5.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.3.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.10.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bleach>=3.1.1->swifter) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach>=3.1.1->swifter) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->modin[ray]>=0.8.1.1->swifter) (2.4.7)\n",
            "Requirement already satisfied: redis<3.5.0,>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.4.1)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.5.4)\n",
            "Requirement already satisfied: aioredis in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.3.1)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.0.12)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.6.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.7.0)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (2.0.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (2.23.0)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.3.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (2.6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (5.3.1)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.7.11)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.4.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.7.3)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.6/dist-packages (from partd>=0.3.10; extra == \"dataframe\"->dask[dataframe]>=2.10.0->swifter) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.3.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (50.3.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.1.1)\n",
            "Requirement already satisfied: hiredis in /usr/local/lib/python3.6/dist-packages (from aioredis->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.1.0)\n",
            "Requirement already satisfied: async-timeout in /usr/local/lib/python3.6/dist-packages (from aioredis->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.0.1)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.7)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (7.352.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (4.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.0.4)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.1.2)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.16.0)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (20.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (5.0.2)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.9.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (2.11.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.5.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.2.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (20.0.0)\n",
            "Requirement already satisfied: contextvars; python_version >= \"3.6\" and python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencensus-context==0.1.2->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (2.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.52.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.17.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.1.1)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars; python_version >= \"3.6\" and python_version < \"3.7\"->opencensus-context==0.1.2->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.14)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.4.8)\n",
            "Your password\n",
            ">> \n",
            "\n",
            "[  ]  Welcome I_am_Zeus_AI \n",
            "\n",
            "\n",
            "[  ] You have not yet selected any challenge.\n",
            "\n",
            "__________________________________________________________________________________________________________________________________\n",
            "|     |              |                  |                    |          \n",
            "|index|  challenge   |     problem      |       reward       |    id    \n",
            "|     |              |                  |                    |          \n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  0  |Public Compet |  Classification  |     $7,000 USD     | giz-nlp-agricultural-keyword-spotter...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  1  |Public Compet |    Prediction    |     $6,000 USD     | uber-nairobi-ambulance-perambulation-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  2  |Public Compet |    Prediction    |     $3,000 USD     | cgiar-crop-yield-prediction-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  3  |Public Compet |Reinforcement Lear| 3000 Zindi Points  | indaba-grand-challenge-curing-leishmaniasis...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  4  |Public Compet |  Classification  |     $2,000 USD     | ai4d-icompass-social-media-sentiment-analysis-for-...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  5  |Public Compet |  Classification  |   Job Interview    | instadeep-enzyme-classification-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  6  |Public Compet |  Classification  | 2000 Zindi Points  | runmila-ai-institute-minohealth-ai-labs-tuberculos...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  7  | Private Hack |                  |     EGP 30,000     | umojahack-egypt...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  8  | Private Hack |    Prediction    |     Knowledge      | dsea-financial-inclusion-in-africa...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "|  9  | Private Hack |    Prediction    |     Knowledge      | pyladies-financial-inclusion-in-africa...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 10  | Private Hack |    Prediction    |    NGN 750,000     | umojahack-nigeria...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 11  | Private Hack |  Classification  |      100 TND       | xente-fraud-dection-hackathon...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 12  |Public Compet |    Prediction    |     Knowledge      | local-ocean-conservation-sea-turtle-face-detection...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 13  | Private Hack |    Prediction    |     Knowledge      | edsa-2021-sendy-logistics-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 14  |Public Compet |  Classification  |     Knowledge      | zindiweekendz-learning-to-vaccinate-or-not-to-vacc...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 15  |Public Compet |  Classification  |     Knowledge      | swahili-news-classification...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 16  |Public Compet |    Prediction    |     Knowledge      | zindiweekendz-learning-urban-air-pollution-challen...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 17  |Public Compet |  Classification  |     Knowledge      | zindiweekendz-learning-covid-19-tweet-classificati...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 18  |Public Compet |    Prediction    |     Knowledge      | zindiweekendz-learning-south-african-covid-19-vuln...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 19  |Public Compet | Computer Vision  |     Knowledge      | zindiweekendz-learning-spot-the-mask-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 20  |Public Compet |    Prediction    |     Knowledge      | data-science-nigeria-2019-challenge-1-insurance-pr...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 21  |Public Compet |  Classification  |     Knowledge      | ai-hack-tunisia-6-predictive-analytics-challenge-3...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 22  |Public Compet | Computer Vision  |     Knowledge      | ai-hack-tunisia-2-computer-vision-challenge-2...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 23  |Public Compet |  Classification  |     Knowledge      | ai-hack-tunisia-1-computer-vision-challenge-1...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 24  |Public Compet |    Prediction    |     Knowledge      | ai-tunisia-hack-5-predictive-analytics-challenge-2...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 25  |Public Compet |  Classification  |     Knowledge      | ai-hack-tunisia-4-predictive-analytics-challenge-1...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 26  |Public Compet | Computer Vision  |     Knowledge      | miia-pothole-image-classification-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 27  |Public Compet | Computer Vision  |     Knowledge      | sbtic-animal-classification...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 28  |Public Compet |    Prediction    |     Knowledge      | financial-inclusion-in-africa...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 29  |Public Compet | Computer Vision  |     Knowledge      | cmu-africa-data-science-club-challenge-1-computer-...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 30  |Public Compet |    Prediction    |     Knowledge      | data-science-nigeria-challenge-2-recommendation-en...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 31  |Public Compet |    Prediction    |     Knowledge      | data-science-nigeria-challenge-1-loan-default-pred...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 32  |Public Compet |    Prediction    |    $12,000 USD     | traffic-jam-predicting-peoples-movement-into-nairo...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 33  |Public Compet |  Classification  |    $11,000 USD     | farm-pin-crop-detection-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 34  |Public Compet |     Forecast     |    $10,000 USD     | 2030-vision-flood-prediction-in-malawi...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 35  |Public Compet |     Forecast     |     $8,000 USD     | wazihub-soil-moisture-prediction-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 36  |Public Compet |    Prediction    |     $7,000 USD     | sendy-logistics-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 37  |Public Compet |    Collection    |     $6,000 USD     | ai4d-african-language-dataset-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 38  |Public Compet |    Prediction    |     $5,500 USD     | uber-movement-sanral-cape-town-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 39  |Public Compet |    Prediction    |     $5,000 USD     | zimnat-insurance-recommendation-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 40  |Public Compet |     Forecast     |     $5,000 USD     | airqo-ugandan-air-quality-forecast-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 41  |Public Compet |     Forecast     |     $5,000 USD     | predict-the-global-spread-of-covid-19...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 42  |Public Compet | Computer Vision  |     $5,000 USD     | iclr-workshop-challenge-2-radiant-earth-computer-v...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 43  |Public Compet | Computer Vision  |     $5,000 USD     | iclr-workshop-challenge-1-cgiar-computer-vision-fo...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 44  |Public Compet |  Visualisation   |     $5,000 USD     | 2030-vision-data-visualization-and-reporting-chall...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 45  |Public Compet |    Prediction    |     $5,000 USD     | womxn-in-big-data-south-africa-female-headed-house...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 46  |Public Compet |  Classification  |     $4,500 USD     | xente-fraud-detection-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 47  |Public Compet |  Classification  |     $4,200 USD     | basic-needs-basic-rights-kenya-tech4mentalhealth...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 48  |Public Compet | Computer Vision  |     $3,000 USD     | cgiar-wheat-growth-stage-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 49  |Public Compet |    Prediction    |     $3,000 USD     | akeed-restaurant-recommendation-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 50  |Public Compet |  Visualisation   |     $3,195 USD     | animal-insights-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 51  |Public Compet |    Prediction    | 2000 Zindi Points  | sbtic-xente-credit-scoring-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 52  |Public Compet |  Visualisation   |     $3,000 USD     | ai-art... \n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 53  |Public Compet |    Prediction    |Cash and prizes wort| mobile-money-and-financial-inclusion-in-tanzania-c...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 54  |Public Compet |  Classification  | 2000 Zindi Points  | fowl-escapades...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 55  |Public Compet |     Forecast     | 2000 Zindi Points  | sea-turtle-rescue-forecast-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 56  |Public Compet |  Classification  | 2000 Zindi Points  | tic-heap-cirta-particle-classification-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 57  |Public Compet |     Forecast     | 2000 Zindi Points  | mtoto-news-childline-kenya-call-volume-prediction-...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 58  |Public Compet |  Classification  |Cash and prizes wort| sea-turtle-rescue-error-detection-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 59  |Public Compet |  Classification  |     $1,000 USD     | sustainable-development-goals-sdgs-text-classifica...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 60  |Public Compet |    Prediction    |     $1,000 USD     | social-media-prediction-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 61  |Public Compet |    Prediction    |  500 Zindi Points  | busara-mental-health-prediction-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 62  | Private Hack |    Prediction    |     Knowledge      | xente-credit-scoring-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 63  | Private Hack |    Prediction    |     Knowledge      | cmu-africa-fighting-fire-with-data...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 64  | Private Hack |  Classification  |     MAD 37,000     | umojahack-morocco...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 65  | Private Hack |  Classification  |     DT 11,000      | umojahack-tunisia...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 66  | Private Hack |    Prediction    |     $1,000 USD     | umojahack-zimbabwe...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 67  | Private Hack |    Prediction    |       R3,000       | uct-datathon-the-ultimate-hacking-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 68  | Private Hack |  Classification  |      100 TND       | supcom-tunisian-fraud-detection-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 69  | Private Hack |    Prediction    |     Knowledge      | dsn-ai-bootcamp-qualification-hackathon...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 70  | Private Hack |    Prediction    |     Knowledge      | expresso-churn-prediction-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 71  | Private Hack |  Classification  |     Knowledge      | instadeep-fraud-detection-in-electricity-and-gas-c...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 72  | Private Hack |    Prediction    |     Knowledge      | dsn-pre-bootcamp-hackathon-the-excellent-store-cha...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 73  | Private Hack |    Prediction    |     Knowledge      | dsn-pre-bootcamp-hackathon-expresso-churn-predicti...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 74  | Private Hack |     Forecast     |     Knowledge      | zindi-mentorship-3-childline-kenya-call-volume-pre...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 75  |Public Compet |    Prediction    |    $25,000 USD     | usaids-intelligent-forecasting-challenge-model-fut...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 76  | Private Hack |    Prediction    |    DZD 510,000     | umojahack-algeria-yassir-eta-prediction-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 77  | Private Hack |    Prediction    |    172,000 ZAR     | umojahack-south-africa-yassir-eta-prediction-chall...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 78  | Private Hack |    Prediction    |     Knowledge      | urban-air-pollution-hackathon...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 79  | Private Hack |    Prediction    |     Knowledge      | zindi-mentorship-2-sendy-logistics-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 80  | Private Hack |  Classification  |     Knowledge      | tunisian-fraud-detection-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 81  | Private Hack |  Classification  |     Knowledge      | edsa-to-vaccinate-or-not-to-vaccinate-its-not-a-qu...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 82  | Private Hack |    Prediction    |   2,331,000 FCFA   | umojahack-senegal-challenge-expresso-sur-la-predic...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 83  | Private Hack |    Prediction    |     GHC 23,200     | umojahack-ghana-expresso-churn-prediction-challeng...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 84  | Private Hack |    Prediction    |   RWF 3,800,000    | umojahack-rwanda-expresso-churn-prediction-challen...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 85  | Public Hack  |    Prediction    |     Knowledge      | fighting-fire-with-data-hackathon...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 86  | Public Hack  |  Classification  |    225,000 Tsh     | swahili-news-classification-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 87  | Private Hack |    Prediction    |     Knowledge      | zindi-mentorship-1-financial-inclusion-in-africa...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 88  | Public Hack  | Computer Vision  |     $1,000 USD     | sansa-informal-settlements-in-south-africa...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 89  | Private Hack |    Prediction    |     Knowledge      | insurance-prediction...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 90  | Private Hack |    Prediction    |     Knowledge      | dsn-ai-club-unilag-sendy-logistics-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 91  | Public Hack  |    Prediction    |      $300 USD      | the-zimnat-insurance-assurance-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 92  | Public Hack  |    Prediction    |      $300 USD      | akeed-restaurant-recommendation-hackathon...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 93  | Private Hack |    Prediction    |     Knowledge      | edsa-sendy-logistics-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 94  | Public Hack  |  Classification  |      $300 USD      | covid-19-tweet-classification-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 95  | Private Hack |    Prediction    |     Knowledge      | alu-rwanda-sendy-logistics-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 96  | Public Hack  |  Classification  |      $300 USD      | to-vaccinate-or-not-to-vaccinate-its-not-a-questio...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 97  | Public Hack  | Computer Vision  |      $300 USD      | spot-the-mask-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 98  | Public Hack  |    Prediction    |      $300 USD      | urban-air-pollution-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 99  | Public Hack  |    Prediction    |      $300 USD      | south-african-covid-19-vulnerability-map...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 100 | Private Hack |    Prediction    |      $400 USD      | umojahack-3-hotspots...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 101 | Private Hack | Computer Vision  |     $1,000 USD     | umojahack-1-saeon-identifying-marine-invertebrates...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 102 | Private Hack |     Forecast     |      $600 USD      | umojahack-2-xente-purchase-prediction-challenge...\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "| 103 |Public Compet |Reinforcement Lear|     Knowledge      | ibm-malaria-challenge...\n",
            "__________________________________________________________________________________________________________________________________\n",
            "\n",
            "\n",
            "Type the index of the challenge you want to select or 'q' to exit.\n",
            ">>0\n",
            "\n",
            "[  ] You choose the challenge : giz-nlp-agricultural-keyword-spotter,\n",
            "\tClassify audio utterances in Luganda and English from Uganda.\n",
            "\n",
            "data/nlp_keywords_29Oct2020.zip: 100% 28.7M/28.7M [00:20<00:00, 1.49Mo/s]\n",
            "data/AdditionalUtterances.zip: 100% 43.6M/43.6M [00:06<00:00, 7.36Mo/s]\n",
            "data/StarterNotebook.ipynb: 100% 451k/451k [00:00<00:00, 874ko/s]\n",
            "data/audio_files.zip:  71% 286M/400M [47:56<19:08, 104ko/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"init.py\", line 50, in <module>\n",
            "    main(parser)\n",
            "  File \"init.py\", line 45, in main\n",
            "    if args.download: download(args)\n",
            "  File \"init.py\", line 22, in download\n",
            "    user.download_dataset(args.data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zindi/user.py\", line 228, in download_dataset\n",
            "    for data in datafiles]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zindi/user.py\", line 228, in <listcomp>\n",
            "    for data in datafiles]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zindi/utils.py\", line 32, in download\n",
            "    for data in response.iter_content(chunk_size=1024):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/models.py\", line 751, in generate\n",
            "    for chunk in self.raw.stream(chunk_size, decode_content=True):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/response.py\", line 496, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/response.py\", line 444, in read\n",
            "    data = self._fp.read(amt)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 463, in read\n",
            "    n = self.readinto(b)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 507, in readinto\n",
            "    n = self.fp.readinto(b)\n",
            "  File \"/usr/lib/python3.6/socket.py\", line 586, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.6/ssl.py\", line 1012, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.6/ssl.py\", line 874, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "  File \"/usr/lib/python3.6/ssl.py\", line 631, in read\n",
            "    v = self._sslobj.read(len, buffer)\n",
            "KeyboardInterrupt\n",
            "unzip:  cannot find or open data/raw/audio_files.zip, data/raw/audio_files.zip.zip or data/raw/audio_files.zip.ZIP.\n",
            "unzip:  cannot find or open data/raw/AdditionalUtterances.zip, data/raw/AdditionalUtterances.zip.zip or data/raw/AdditionalUtterances.zip.ZIP.\n",
            "unzip:  cannot find or open data/raw/nlp_keywords_29Oct2020.zip, data/raw/nlp_keywords_29Oct2020.zip.zip or data/raw/nlp_keywords_29Oct2020.zip.ZIP.\n",
            "[Errno 2] No such file or directory: '/content/data/audio_files/IV38R7F.wav'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyZqCqu4A_b2",
        "outputId": "31e4e7be-860c-4ecb-9b82-872a16fed23e"
      },
      "source": [
        "!./train.sh"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-29 18:14:44.947717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 108, in <module>\n",
            "    df = pd.read_csv(args.train_csv_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 688, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 454, in _read\n",
            "    parser = TextFileReader(fp_or_buf, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 948, in __init__\n",
            "    self._make_engine(self.engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 1180, in _make_engine\n",
            "    self._engine = CParserWrapper(self.f, **self.options)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 2010, in __init__\n",
            "    self._reader = parsers.TextReader(src, **kwds)\n",
            "  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n",
            "  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/data/final_train.csv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFizAB7-Bf4f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}